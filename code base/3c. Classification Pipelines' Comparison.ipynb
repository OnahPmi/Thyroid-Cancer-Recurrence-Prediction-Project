{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caadb4d",
   "metadata": {},
   "source": [
    "# Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15393646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay, DetCurveDisplay, confusion_matrix\n",
    "\n",
    "# Data encoding and Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Dimensionality Reduction and Clustering Algorithms\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Data spliting and Cross Validation and Performance Metrics\n",
    "from sklearn.model_selection import train_test_split as tts, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import recall_score, f1_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import  make_scorer,  precision_score, accuracy_score\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.neural_network import MLPClassifier as FNN\n",
    "\n",
    "from collections import defaultdict as dd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e391b5b",
   "metadata": {},
   "source": [
    "# Perform Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f8087d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dl_env\\lib\\site-packages\\scipy\\stats\\_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for FNN\n",
      "PCA pipeline t-SVD pipeline  p-value\n",
      "      PCA-RF        tSVD-RF   0.8316\n",
      "      PCA-GB        tSVD-GB   0.0929\n",
      "     PCA-SVM       tSVD-SVM   0.1730\n",
      "      PCA-LR        tSVD-LR   0.4982\n",
      "     PCA-KNN       tSVD-KNN   0.0422\n",
      "     PCA-FNN       tSVD-FNN   0.0137\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Thyroid_Diff.csv\")\n",
    "\n",
    "X = data.drop(\"Recurred\", axis=1)\n",
    "y = data[\"Recurred\"]\n",
    "y = y.map({\"No\":0,\"Yes\":1})\n",
    "\n",
    "# Define preprocessor\n",
    "num_features = list(X.columns[:1])\n",
    "cat_features = list(X.columns[1:])\n",
    "\n",
    "# Define the numerical transformer\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), \n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Define the categorical transformer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "# Define your ColumnTransformer (preprocessor)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Compute sample weights based on class imbalance\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y)\n",
    "\n",
    "\n",
    "# Define the models using the best parameters from hyperparameter tuning\n",
    "models_pca = {\n",
    "    \"RF\": RFC(criterion='entropy', max_depth=None, max_features='log2', min_samples_leaf=4, min_samples_split=6, \n",
    "              n_estimators=403),\n",
    "    \"GB\": GBC(criterion='friedman_mse', learning_rate=0.35, loss='exponential', max_depth=6, n_estimators=150, tol=1e-12),\n",
    "    \"SVM\": SVC(probability=True, C=0.1, kernel='sigmoid', tol=0.001),\n",
    "    \"LR\": LR(C=0.36, penalty='l1', solver='liblinear'),\n",
    "    \"KNN\": KNN(n_neighbors=17, p=2, weights='distance'),\n",
    "    \"FNN\": FNN(activation='relu', alpha=0.5, early_stopping=True, hidden_layer_sizes=(300,), learning_rate='adaptive', \n",
    "               max_iter=10000, solver='lbfgs', tol=1e-05),\n",
    "}\n",
    "\n",
    "models_tsvd = {\n",
    "    \"RF\": RFC(criterion='entropy', max_depth=None, max_features='log2', \n",
    "              min_samples_leaf=3, min_samples_split=6, n_estimators=400),\n",
    "    \"GB\": GBC(criterion='squared_error', learning_rate=0.3, loss= 'log_loss', \n",
    "              max_depth=4, n_estimators=125, tol=1e-10),\n",
    "    \"SVM\": SVC(probability=True, C=0.25, kernel='sigmoid', tol=0.01),\n",
    "    \"LR\": LR(C=0.1, max_iter=5000, penalty='l2', solver='liblinear', tol=0.001),\n",
    "    \"KNN\": KNN(n_neighbors=18, p=4, weights='distance'),\n",
    "    \"FNN\": FNN(activation='identity', alpha=1.0, early_stopping=True, hidden_layer_sizes=(125, 155), \n",
    "               learning_rate='constant', max_iter=15000, solver='adam', tol=0.001),\n",
    "}\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "tsvd = TruncatedSVD(n_components=5)\n",
    "\n",
    "# Set up Stratified K-Fold Cross-Validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=420)\n",
    "\n",
    "# Dictionary to store Wilcoxon test results\n",
    "wilcoxon_results = {}\n",
    "\n",
    "for (model_name_pca, model_pca), (model_name_tsvd, model_tsvd) in zip(models_pca.items(), models_tsvd.items()):\n",
    "    \n",
    "    print(f\"\\nComparing PCA vs t-SVD for {model_name_pca}\")\n",
    "    \n",
    "    # Build pipelines\n",
    "    pipeline_pca = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"pca\", pca),\n",
    "        (\"clf\", model_pca),\n",
    "    ])\n",
    "\n",
    "    pipeline_tsvd = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"pca\", tsvd),\n",
    "        (\"clf\", model_tsvd),\n",
    "    ])\n",
    "\n",
    "    # Cross-validation scores (e.g., balanced accuracy)\n",
    "    scores_pca = cross_val_score(pipeline_pca, X, y, cv=skf, scoring=\"balanced_accuracy\")\n",
    "    scores_tsvd = cross_val_score(pipeline_tsvd, X, y, cv=skf, scoring=\"balanced_accuracy\")\n",
    "\n",
    "    # Wilcoxon signed-rank test (non-parametric paired comparison)\n",
    "    stat, p = wilcoxon(scores_pca, scores_tsvd)\n",
    "\n",
    "    # Store the results\n",
    "    wilcoxon_results[model_name_pca] = {\n",
    "        \"PCA_mean\": scores_pca.mean(),\n",
    "        \"tSVD_mean\": scores_tsvd.mean(),\n",
    "        \"statistic\": stat,\n",
    "        \"p_value\": p\n",
    "    }\n",
    "\n",
    "# Create a list to hold rows of the DataFrame\n",
    "results_table = []\n",
    "\n",
    "for model, res in wilcoxon_results.items():\n",
    "    row = {\n",
    "        \"PCA pipeline\": f\"PCA-{model}\",\n",
    "        \"t-SVD pipeline\": f\"tSVD-{model}\",\n",
    "        \"p-value\": round(res[\"p_value\"], 4)\n",
    "    }\n",
    "    results_table.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "wilcoxon_df = pd.DataFrame(results_table)\n",
    "wilcoxon_df.to_csv(\"../results/Wilcoxon Test Results.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(wilcoxon_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e7e2d",
   "metadata": {},
   "source": [
    "# Perform McNemar’s test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a412384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing PCA vs t-SVD for RF\n",
      "\n",
      "Comparing PCA vs t-SVD for GB\n",
      "\n",
      "Comparing PCA vs t-SVD for SVM\n",
      "\n",
      "Comparing PCA vs t-SVD for LR\n",
      "\n",
      "Comparing PCA vs t-SVD for KNN\n",
      "\n",
      "Comparing PCA vs t-SVD for FNN\n",
      "\n",
      "RF - McNemar’s test results:\n",
      "b (PCA correct, t-SVD wrong): 2\n",
      "c (t-SVD correct, PCA wrong): 0\n",
      "Statistic: 0.5000, p-value: 0.4795\n",
      "\n",
      "GB - McNemar’s test results:\n",
      "b (PCA correct, t-SVD wrong): 5\n",
      "c (t-SVD correct, PCA wrong): 5\n",
      "Statistic: 0.1000, p-value: 0.7518\n",
      "\n",
      "SVM - McNemar’s test results:\n",
      "b (PCA correct, t-SVD wrong): 4\n",
      "c (t-SVD correct, PCA wrong): 0\n",
      "Statistic: 2.2500, p-value: 0.1336\n",
      "\n",
      "LR - McNemar’s test results:\n",
      "b (PCA correct, t-SVD wrong): 1\n",
      "c (t-SVD correct, PCA wrong): 0\n",
      "Statistic: 0.0000, p-value: 1.0000\n",
      "\n",
      "KNN - McNemar’s test results:\n",
      "b (PCA correct, t-SVD wrong): 2\n",
      "c (t-SVD correct, PCA wrong): 1\n",
      "Statistic: 0.0000, p-value: 1.0000\n",
      "\n",
      "FNN - McNemar’s test results:\n",
      "b (PCA correct, t-SVD wrong): 9\n",
      "c (t-SVD correct, PCA wrong): 0\n",
      "Statistic: 7.1111, p-value: 0.0077\n"
     ]
    }
   ],
   "source": [
    "# Split into train-test sets\n",
    "X_train, X_test, y_train, y_test = tts(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# Fit and compare pipelines for each model\n",
    "results_mcnemar = {}\n",
    "\n",
    "for (model_name_pca, model_pca), (model_name_tsvd, model_tsvd) in zip(models_pca.items(), models_tsvd.items()):\n",
    "    \n",
    "    print(f\"\\nComparing PCA vs t-SVD for {model_name_pca}\")\n",
    "    \n",
    "    # Build PCA pipeline\n",
    "    pipeline_pca = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", pca),\n",
    "            (\"clf\", model_pca),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Build t-SVD pipeline\n",
    "    pipeline_tsvd = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", tsvd),\n",
    "            (\"clf\", model_tsvd),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit both on training data\n",
    "    pipeline_pca.fit(X_train, y_train)\n",
    "    pipeline_tsvd.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred_pca = pipeline_pca.predict(X_test)\n",
    "    y_pred_tsvd = pipeline_tsvd.predict(X_test)\n",
    "    \n",
    "    # Build contingency table for McNemar's test\n",
    "    table = confusion_matrix(y_pred_pca, y_pred_tsvd, labels=[0, 1])\n",
    "    \n",
    "    # Format table as required by McNemar's test:\n",
    "    #            tSVD\n",
    "    #           0    1\n",
    "    #   PCA 0  [a,   b]\n",
    "    #        1 [c,   d]\n",
    "    b = np.sum((y_pred_pca == 1) & (y_pred_tsvd == 0))\n",
    "    c = np.sum((y_pred_pca == 0) & (y_pred_tsvd == 1))\n",
    "    \n",
    "    mcnemar_result = mcnemar([[0, b], [c, 0]], exact=False, correction=True)\n",
    "\n",
    "    results_mcnemar[model_name_pca] = {\n",
    "        \"b\": b,\n",
    "        \"c\": c,\n",
    "        \"statistic\": mcnemar_result.statistic,\n",
    "        \"p_value\": mcnemar_result.pvalue,\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for model, result in results_mcnemar.items():\n",
    "    print(f\"\\n{model} - McNemar’s test results:\")\n",
    "    print(f\"b (PCA correct, t-SVD wrong): {result['b']}\")\n",
    "    print(f\"c (t-SVD correct, PCA wrong): {result['c']}\")\n",
    "    print(f\"Statistic: {result['statistic']:.4f}, p-value: {result['p_value']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning Kernel",
   "language": "python",
   "name": "deep_learning_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
